\documentclass{book}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox, eqparbox, hhline}
\usepackage{mathtools}
% \usepackage{caption}
\usepackage{mdframed}

\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}

\makeatletter
\newcases{lrdcases}
  {\quad}
  {$\m@th\displaystyle{##}$\hfil}
  {$\m@th\displaystyle{##}$\hfil}
  {\lbrace}
  {\rbrace}
\newcases{lrdcases*}
  {\quad}
  {$\m@th\displaystyle{##}$\hfil}
  {{##}\hfil}
  {\lbrace}
  {\rbrace}
\makeatother

\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}

% \usepackage[executivepaper,margin=1in]{geometry}
% \usepackage[charter]{mathdesign}

% \title{\textbf{Inteligência Artificial em \textit{Magic: The Gathering}}}
% \author{Guilherme Souto Schützer - 8658544 \\
%         Tomás Bezerra Marcondes Paim - 7157602 \\
        % \begin{figure}[]
        % \centering
        %     \includegraphics[width=0.25\textwidth]{picstcc/ime.png}
        % \end{figure}}
% \date{2017}


\begin{document}

  \begin{titlepage}
  \begin{center}
   {\huge\bfseries Inteligência Artificial \\ em \textit{Magic: the Gathering}\\}
   % ----------------------------------------------------------------
   \vspace{1.5cm}
   {\bfseries Guilherme Souto Schützer}\\[5pt]
   guischutzer@gmail.com\\[14pt]
   \vspace{0.5cm}
   {\bfseries Tomás Marcondes Bezerra Paim}\\[5pt]
   tomasbmp@gmail.com\\[14pt]
    % ----------------------------------------------------------------
   \vspace{2cm}
  {\begin{figure}[!h]
          \centering
              \includegraphics[width=0.25\textwidth]{picstcc/ime.png}
  \end{figure}}
   \vspace{0.4cm}
 \end{center}
  \end{titlepage}

\chapter*{Objetivo}
\textbf{Magic: The Gathering} é um jogo de cartas criado em 1993 por
Richard Garfield que introduziu o conceito moderno de \textit{trading
card game} (jogo de cartas colecionáveis). Com um acervo de mais de 15
mil cartas diferentes, os jogadores devem criar baralhos de 60 cartas
(normalmente podendo haver repetição de até quatro cartas iguais) e
competir, normalmente em jogos um contra um.
\par Durante o jogo, os jogadores têm que lidar com informações
conhecidas (as cartas já jogadas previamente e as cartas em suas mãos) e
informações desconhecidas (as cartas na mão de seu oponente e a ordem
das cartas em seu baralho), o que faz com que seja praticamente
impossível ter informação perfeita. Além disso, ambos os jogadores podem
agir a praticamente qualquer momento dentro de um turno, o que adiciona
uma camada a mais de complexidade.
\par Já existem inteligências artificiais feitas para jogar
\textbf{Magic}, mas devido à complexidade do jogo, nenhuma inteligência
artificial consegue ser realmente boa no jogo (por exemplo, elas não
costumam levar em consideração as cartas que estão na sua mão, então é
muito fácil fazer com que a IA sempre ``morda sua isca'').
\par Nosso objetivo com o trabalho será entender o problema e criar a
nossa versão de uma inteligência artificial para uma versão simplificada
do jogo (limitando o conjunto de cartas disponíveis, adicionando
restrições à construção dos baralhos e simplificando algumas regras do
jogo).

\chapter{Introdução}

Inteligência artificial é um campo da ciência da computação que estuda
"agentes inteligentes", que de certa forma percebem o ambiente à sua volta
e tomam ações tendo como objetivo maximizar a chance de sucesso de alguma
tarefa específica. Uma utilização muito comum nos dias de hoje é a de
inteligência artificial com o objetivo de criar um agente capaz de competir
com humanos em jogos com alto nível de estratégia, como Xadrez e Go.
Decidimos então estudar inteligência artificial para a realização deste
trabalho com a ideia de modelar um outro jogo de estratégia,
\textbf{Magic: The Gathering}.

\textit{Magic} foi lançado em 1993, introduzindo o conceito de trading card
game. Com o sucesso do jogo e popularização dos jogos digitais, eventualmente
nasceram versões digitais do jogo para computadores e videogames, e com isso
nasceu a necessidade de agentes que jogassem contra os jogadores. Atualmente
há várias versões digitais de Magic, mas nenhuma tem uma inteligência artificial
boa o suficiente para se provar desafiadora contra jogadores experientes, uma vez
que a cada ação há uma grande quantidade de ações possíveis e elementos como
blefe envolvidos. Nossa intenção é entender a complexidade da representação do
jogo e criar uma plataforma para jogar Magic que possibilite a implementação de
um agente de inteligência artificial.

Na próxima seção iremos introduzir alguns conceitos e regras básicas do jogo,
de modo a possibilitar a familiarização do leitor com \textbf{Magic}, facilitando
a compreensão do restante do trabalho.

\section{Conceitos básicos}

Um jogo usual de \textit{Magic: the Gathering} conta com dois jogadores munidos
de um baralho de 60 cartas cada, ambos começando com 20 pontos de vida, sendo
que o objetivo é reduzir o total de pontos de vida do oponente a 0. Para tanto,
é preciso usar as cartas disponíveis na mão, que podem representar feitiços,
criaturas ou terrenos (existem outros tipos de cartas, mas para nossa implementação
iremos focar nesses três). Feitiços são cartas que têm um efeito que acontece
no momento em que são jogadas e então são colocadas no cemitério (como é chamada
a pilha de descarte no jogo).

\vskip1ex

Por exemplo, o feitiço Divinação tem um efeito simples: "Compre dois
cards" (na versão em português do jogo, as cartas são referenciadas pela palavra
em inglês \textit{cards}). O jogador que joga esta carta pega as duas cartas do
topo de seu baralho e as coloca em sua mão, aumentando o leque de possibilidades.
Assim, \textbf{feitiços} podem alterar o estado do jogo de diversas maneiras
(como fazer com que os jogadores comprem ou descartem cartas, alterar o total de
pontos de vida de um jogador ou destruir uma criatura) e são a principal forma
de interagir com o oponente ou desenvolver o seu lado do campo de batalha (como
é chamada a zona do jogo em que ficam as criaturas e terrenos).

\begin{figure}[!h]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.5\textwidth]{picstcc/divination.jpg}
        \caption{Divinação (Feitiço)}
        \label{divination}
    \end{minipage}\hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=0.5\textwidth]{picstcc/angelOfMercy.jpg}
        \caption{Anjo da Misericórdia (Criatura)}
        \label{anjo}
    \end{minipage}
\end{figure}

\textbf{Criaturas} são cartas permanentes (uma vez jogadas elas
permanecem no campo de batalha até que sejam destruídas por algum
feitiço ou durante o combate) que possuem poder (quantidade de dano
causado em combate), resistência (quantidade de dano necessária para ser
destruída) e muitas vezes habilidades que afetam o andamento do combate
ou que fazem algum efeito no momento em que são jogadas.

\vskip1ex

Por exemplo, Anjo da Misericórdia tem a habilidade de Voar (que limita
as interações do oponente durante o combate) e concede a seu controlador
3 pontos de vida ao entrar no campo de batalha. Além disso, seu poder e
resistência são 3 e 3, respectivamente, conforme indicado na caixa no
canto inferior direito.

\vskip1ex

\textbf{Terrenos} são a fonte de \textit{mana}, que é o recurso utilizado para
pagar por criaturas e feitiços. O custo de \textit{mana} das cartas que não são
terreno está indicado no canto superior direito da carta (por exemplo, para
jogar Divinação é necessário usar três terrenos, sendo que um deles deve ser
necessariamente uma Ilha, como na figura \ref{ilha}). Terrenos são, portanto, um
dos tipos de cartas mais importantes, pois sem eles não há maneira (normalmente)
de jogar suas outras cartas. Uma vez utilizado, um terreno se torna \textbf{virado}
(em inglês, \textit{tapped}): para jogar uma carta que não seja terreno, é
necessário virar o número de terrenos equivalente ao seu custo. Uma vez virado,
o terreno permanece virado até o começo do próximo turno de seu controlador,
quando poderão ser utilizados novamente. Desta maneira, são necessários quatro
terrenos para se jogar duas cartas custando duas manas cada durante o mesmo turno.

\begin{wrapfigure}{R}{5cm}
    \centering
    \includegraphics[width=0.25\textwidth]{picstcc/island.jpg}
    \caption{Ilha (Terreno)}
    \label{ilha}
\end{wrapfigure}

Uma parte importante do jogo é o sistema de \textit{cores}. As cartas do jogo
são divididas entre cinco cores de mana, com um terreno associado que produz
mana desta cor: Branco (Planície), Azul (Ilha), Preto (Pântano), Vermelho
(Montanha) e Verde (Floresta). Cada cor tem mecânicas de jogo únicas, fazendo
com que jogadores usem mais de uma cor de mana em seus baralhos para ter acesso
a tipos de efeitos diferentes, ao custo de utilizar terrenos variados, criando
a possibilidade de não ter o terreno certo para jogar a carta desejada.

Para este trabalho utilizaremos apenas baralhos de uma única cor.

\vskip1ex

\section{O jogo}

No começo do jogo é decidido aleatoriamente quem será o jogador inicial,
e então os dois jogadores compram uma mão inicial de sete cartas.
Antes do jogo propriamente dito começar, os jogadores podem optar por tomar uma
ação chamada \textit{mulligan}, que consiste em rejeitar a mão inicial, embaralhá-la
de volta com o restante dos cards e comprar uma nova mão inicial, com uma carta
a menos. Pode-se então repetir o processo até que cada jogador esteja satisfeito
com a mão inicial ou até o jogador realizar um mulligan com apenas uma carta na
mão (resultando em uma mão de zero cartas, onde não há mais a possibilidade de
realizar mulligan). Uma vez que os dois jogadores tiverem escolhido manter uma
mão inicial, cada jogador que realizou pelo menos um mulligan olha a carta do
topo de seu \textit{deck} (como é chamado o baralho) e decide se quer colocá-la
no fundo.

\vskip1ex

O jogo então começa, com os jogadores alternando entre turnos, onde o
jogador que ``controla o turno'' é chamado de \textit{jogador ativo},
com a seguinte estrutura, simplificada:

\begin{itemize}
    \item\textbf{Início do turno}: Permanentes do jogador ativo são
desviradas. Jogador ativo compra uma carta de seu \textit{deck}.
    \item\textbf{Primeira Fase Principal}: Jogador ativo pode jogar as
cartas da mão.
    \item \textbf{Combate}: Jogador ativo ``declara atacantes'' (escolhe
quais de suas criaturas irão atacar seu oponente); em seguida, seu
oponente ``declara bloqueadores'' (escolhe quais de suas criaturas irão
bloquear as criaturas atacantes). Cada criatura não-bloqueada, então,
causa dano igual ao seu poder ao oponente e todas as criaturas
bloqueadas e bloqueadoras causam dano entre si.
    \item \textbf{Segunda Fase Principal}: Igual à primeira Fase
Principal.
\end{itemize}

A estrutura acima se repete até o jogo terminar, o que acontece
geralmente quando algum jogador chega a 0 pontos de vida,
mas também pode acontecer de outras maneiras como, por exemplo, se o
baralho de um jogador acabar.

\chapter{Modelagem}

Neste capítulo abordaremos um jogo de \textit{Magic} como um problema de
Inteligência Artificial.

\section{\textit{Mulligan}}
A estrutura de um turno, como descrita no primeiro capítulo, será repetida
algumas vezes até o jogo acabar, porém é necessário determinar a mão inicial de
cada jogador e, por isso, trataremos este problema em separado.
Baseando-se na experiência própria, a estrutura do problema do
\textbf{\textit{mulligan}} é notavelmente diferente do resto de um jogo
de \textit{Magic}.
A principal diferença é que apesar de ambos os jogadores tomarem
decisões alternadamente nessa etapa, as ações do oponente não têm
nenhuma influência
direta sobre as ações do agente, que deve se concentrar em obter uma
\textbf{mão inicial} que possibilite jogadas nos primeiros turnos do
jogo.

\vskip1ex

A figura \ref{mulligan} representa as escolhas que o jogador poderá
fazer para determiná-la, com cada conjunto de cartas representando um
conjunto
de estados.

\begin{figure}
  \centering
  \label{mulligan}
  \input{mulligan.tex}
  \caption{Representação visual de um problema de \textit{mulligan}. Cada
nível $i$ representa o número de cartas na mão inicial do jogador. $K$ significa a decisão de manter a mão, $M$ realizar um \textit{mulligan}, $T$ deixar a carta no topo em um \textit{scry} e $B$ colocá-la no fundo.}
\end{figure}

Definimos vagamente uma mão jogável se esta contém tanto cartas que
impactam o estado de jogo e recursos necessários para jogá-las.
Para este efeito, separaremos as cartas do deck em duas categorias:
terrenos (recursos) e não-terrenos (impactam o jogo).
Outro fator importante é o tamanho da mão, pois cada carta perdida
representa um turno de atraso em relação a uma mão com sete cartas (uma
vez que cada jogador compra
uma carta por turno). Dessa maneira, em uma mão com $i$ cartas, temos
$h+1$ possibilidades, cada uma com probabilidade
\begin{equation} \label{eq:stateprob} \mathcal{P}_i(j) =
\frac{\binom{J}{j}\binom{60 - J}{i - j}}{\binom{60}{i}}, \ \
j = 0,\ldots, i, \end{equation} onde $J$ é o número de terrenos no deck
e $j$ o
número de terrenos
na mão. Note que $\sum_{j=0}^{i}P_i(j) = 1, \forall i$. Assim, a cada nível, como é mostrado na figura \ref{mulligan}, o
agente deve decidir entre realizar um \textit{mulligan}
(denotado por $M$), que resultará em uma mão com $i-1$ cartas, sendo $i$
terrenos com probabilidade
 \[ \mathcal{P}_{i - 1}(j) = \frac{\binom{J}{j}\binom{60 - J}{i - 1 -
j}}{\binom{60}{i - 1}}, \ \  j = 0,\ldots, i - 1\]
 ou manter a mão (denotado por $K$), o que termina o problema, seguido
(para $i < 7$) de uma ação \textit{scry}, que permite uma pequena
``filtragrem''
 do deck para os jogadores que já acumularam alguma desvantagem (em
relação ao número de cartas na mão) no processo. Por fim, a decisão
também é influenciada
 pela informação de quem é o jogador inicial, pois ele tem virtualmente
uma carta a menos, dado que no primeiro turno do jogo não se compra uma
carta.

\pagebreak
\subsection{Processo De decisão de Markov}
\label{ssec:mdp}

Processos de Decisão de Markov (em inglês, \textit{Markov Decision Process}, ou \textbf{MDP})
são uma forma de representar alguns problemas de decisão sequenciais.

Para descrever um MDP, usaremos um exemplo com o intuito de tornar a explicação mais didática.
Imagine que um gerente de um galpão tem como objetivo maximizar o lucro esperado para o próximo
ano. A cada mês, o gerente observa quanto há em estoque de cada produto e decide quanto irá pedir
ao distribuir daquele produto para o próximo mês. A demanda mensal de cada produto é desconhecida,
mas segue uma distribuição de probabilidade conhecida. Se o gerente pedir produto demais, terá
custos para manter o estoque, e se pedir de menos, estará perdendo vendas por falta de inventário.
Suponha que o galpão tem capacidade para armazenar $M$ unidades de produto e que os custos e a
distribuição da demanda não muda de mês para mês.

O primeiro conceito de MDP que iremos introduzir é o de \textbf{época de decisão}. Uma época de
decisão é um momento onde uma decisão é tomada. No nosso exemplo, cada época de decisão ocorre
no começo de um mês, quando o gerente deve decidir quanto pedir de cada produto. Chamamos a
quantidade de épocas de decisão de um MDP de \textbf{horizonte}, que pode ser finito ou infinito.
No exemplo, o horizonte é finito de tamanho $12$, um para cada mês do ano no qual o gerente deseja
maximizar seus lucros.

Um MDP pode ser representado por uma tupla $(S, A, P, R)$. $S$ é o conjunto de \textbf{estados}
$s_t$ do problema, onde um estado é uma configuração do problema em uma determinada época de
decisão $t$. No exemplo, cada estado representa o espaço disponível no galpão, que pode variar
de $0$ a $M$.

$A$ é o conjunto de \textbf{ações} $a_t$, onde $t$ é a época de decisão. No exemplo, uma ação
pode ser comprar de $0$ a $M-s_t$ unidades no mês.

Para falar sobre os outros elementos da tupla do MDP, precisamos entrar em detalhes sobre os
custos para pedir o produto ao distribuidor e manter o produto em estoque. Um mês começa com $s_t$
unidades em estoque, e são encomendadas mais $a_t$ unidades, o que gera um custo $c_pedido$ dado
pela função $c_p(a_t)$. Vamos assumir que as unidades sejam pedidas no começo do mês e sejam vendidas
no final do mês. Há, portanto, um custo $c_estoque$ para manter o produto em estoque dado pela função
$c_e(s_t + a_t)$. A probabilidade de que a demanda $D_t$ no mês seja de $j$ unidades é $p_j, j = 0,1,2\ldots$.
Quando o final do mês chegar, o número de unidade vendidas será $x_t = min{D_t, s_t + a_j}$, e o lucro
será dado pela função $l(x_t)$. O número de unidades que começarão o próximo mês em estoque será
$s_{t+1}= s_t + a_t - x_t$.

$RS: S \times A \mapsto \mathbb{R}$ é a função que dá a \textbf{recompensa} esperada por tomar a ação $a_t$
quando o processo está no estado estado $s_t$. No exemplo, $r_t(s_t, a_t) = E[l(x_t)] - c_estoque - c_pedido$.

$P: S \times A \times S \mapsto [0,1]$ é uma função que dá a \textbf{probabilidade} do sistema passar de um estado
para outro, dado uma determinada ação. No nosso exemplo:

\begin{equation*}
  Pr\{s_{t+1} = j|s_t = s, a_t = a\} = \begin{cases}p_{s+a-j} &j\le s + a \\
                                                    \sum\limits_{i=s+a}^\infty &j=0 \\
                                                    0 & j >s+a\end{cases}
\end{equation*}

Uma vez que temos o nosso MDP definido, queremos chegar em uma \textbf{política}, que é o nome dado
ao conjunto das \textbf{regras de decisão}. Uma regra de decisão $d_t(s)$ é uma função $d: S \mapsto A$
que que, dado um estado $s$ na época de decisão $t$, retorna uma ação $a$ que deve ser tomada a partir
daquele estado de modo a maximizar o ganho final. A seguir veremos uma representação de Magic como MDP,
e em seguida como extraímos a política para o processo.

\subsection{Mulligan como um MDP}

Dada a estrutura bem conhecida do problema e sua natureza fixa (temos certeza que acabará em um determinado horizonte), podemos determinar todos os parâmetros de um MDP de horizonte finito para que o agente siga uma política com a inteção de alcançar uma mão ``jogável'' para uma partida de \textit{Magic}.

O conjunto de estados $S$ é composto por um estado inicial $S_I$ (que representa o estado antes do jogador comprar a sua primeira mão inicial),
um estado final absorvente $S_F$ (que representa o jogador após ter decidido manter uma mão) e os estados intermediários, dados por um par
$(i, j), i \in \{ 0, 1, \ldots 7\}, j \in \{ 0, 1, \ldots, i \}$ (que representam os estados onde o jogador tem $i$ cartas na mão, sendo que $j$ são terrenos). Assim, as ações $A(s)$ e as probabilidades $P(s'|s, A(s))$ de cada estado $s$ são definidas da seguinte maneira:

\begin{itemize}
  \item $A(S_I) := \left\{ Start \right\};\  P((7, j) | S_I, Start) =  \mathcal{P}_7(j)$
  \\ \\
   A partir de $S_I$ é possível tomar a ação \textit{Start}, que leva para o estado $(7, j)$ com probabilidade $\mathcal{P}_7(j)$, descrita na equação \ref{eq:stateprob}.

  \item $A(i, j) := \begin{lrdcases} Mulligan, &i \in \{ 1, 2, \ldots, 7\}, j\in \{ 0, 1, \ldots, i\},\\
                                     Keep, &i \in \{ 0, 1, \ldots, 7\}, j\in \{ 0, 1, \ldots, i\} \end{lrdcases}; \\ \vspace{.1cm}\\ P((i - 1, j')| (i, j), Mulligan) = \mathcal{P}_{i-1}(j'),\ \ j' \in \{0,1, \ldots, i-1\}, \\ P(S_F|(i, j), Keep) = 1$
   \\ \\
   A partir de $(i, j)$, analogamente à ação $Start$, temos a ação $Mulligan$, que leva a algum estado $(i -1, j')$. Um detalhe importante é a impossibilidade de $Mulligan$ quando $i = 0$. A outra ação, $Keep$, leva ao estado final.

   \pagebreak

   \item $A(S_F) := \left\{ Wait \right\};\ P(S_F | S_F, Wait = 1)$
   \\ \\ No estado final só há a ação $Wait$, um artifício para que o MDP sempre tenha o mesmo número de épocas de decisão (e constitua um problema de horizonte finito).
\end{itemize}

Por fim, ainda precisamos determinar as recompensas $R\left(s' | s, a \in A(s) \right)$ associadas a cada transição. A notação adotada é $R_k(i, j) = R(S_F | (i, j), Keep)$, ou seja, $R_k(i, j)$ é a recompensa associada à ação $Keep$ a partir estado $(i, j)$ (em alto nível, é a decisão de manter uma mão com $i$ cartas, sendo $j$ delas terrenos). Como a única decisão que realmente importa para a pontuação é a ação $Keep$ (pois esta garante que a mão atual será a mão inicial), determinamos que todas as outras transições tem recompensa $R_0 = 0, \forall R_0 \in R \backslash R_k$. A partir de experiências pessoais, podemos determinar $R_k$ a partir das seguintes restrições:
\begin{itemize}
  \item Com $i= i_0$ fixo e $j\in\{0,1,\ldots,i_0\}$, as recompensas $R_k(i_0, j)$(se existem) devem seguir a
seguinte relação:
  \begin{equation} \label{eq:idealhand}R_k (i_0, 3) > R_k(i_0, 2) > R_k(i_0, 4)
> R_k(i_0, 5) > R_k(i_0, 1) > R_k(i_0, 6) > R_k(i_0, 7) \gg R_k(i_0,
0),\end{equation}
  pois na média, uma mão ideal tem 3 terrenos, em segundo lugar 2
terrenos, etc. Uma mão sem terrenos é considerada \textbf{muito} ruim.
  \item $R_k(i, j) > R_k(i - 1, j), \forall (i, j):$ uma mão com o mesmo
número de terrenos e uma carta a menos deve sempre ser considerada pior
do que a alternativa.
  \item $R_k(i, j) > R_k(i - 1, j - 1), \forall (i, j):$ uma mão com o mesmo
número de não-terrenos e uma carta a menos deve sempre ser considerada
pior do que a alternativa.
\end{itemize}



Dessa maneira, chegamos a uma fórmula geral, $R_k(i, j) = r(j) + \alpha
i$, onde $r(j)$ assume valores pré-determinados de acordo com
as desigualdades \ref{eq:idealhand}. Para $\alpha = 3$ e $r(i)$ determinado pela tabela
\ref{tab:rj}, podemos atribuir as recompensas de acordo com a tabela
\ref{tab:Rij}.

\begin{table}[!h]
\parbox{.45\linewidth}{
\centering
\vspace{0.2cm}
\begin{tabular}{l|r}
$j$  & $r(j)$ \\ \hline
0 & -1000  \\
1 & -4     \\
2 & 0      \\
3 & 1      \\
4 & -1     \\
5 & -3    \\
6 & -5     \\
7 & -7
\end{tabular}
\caption{recompensas-base para $j = 0, \ldots, 7$}
\label{tab:rj}
}
\hfill
\parbox{.45\linewidth}{
\centering
\begin{tabular}{l|rrrrrrrr}
$i \backslash j$ & 0     & 1  & 2  & 3  & 4  & 5  & 6  & 7  \\ \hline
7 & -979  & 17 & 21 & 22 & 20 & 18 & 16 & 14 \\
6 & -982  & 14 & 18 & 19 & 17 & 15 & 13 &    \\
5 & -985  & 11 & 15 & 16 & 14 & 12 &    &    \\
4 & -988  & 8  & 12 & 13 & 11 &    &    &    \\
3 & -991  & 5  & 9  & 10 &    &    &    &    \\
2 & -994  & 2  & 6  &    &    &    &    &    \\
1 & -997  & -1 &    &    &    &    &    &    \\
0 & -1000 &    &    &    &    &    &    &
\end{tabular}
\caption{recompensas de cada estado calculadas com $R_k(i,j) = r(j) + 3i$}
\label{tab:Rij}
}
\end{table}
Assim, temos um MDP de horizonte finito (sempre acabará na época 9) e podemos determinar uma política ótima para a determinação da mão inicial.

EXTRAÇÃO DA POLÍTICA AQUI
A função valor, representada por $v_t(s_t)$, consiste
no máximo de recompensas esperadas totais partindo de um estado $s_t$ com $N-t$ épocas de decisão restante.
\begin{equation*}
  v_t(s_t) = max_a\{r_t(s_t,a_t) + E[v_{t+1}(s_{t+1})]\}
\end{equation*}

\pagebreak

\section{O Jogo}

Um jogo de \textit{Magic: the Gathering} é um problema obviamente mais complexo do que o \textit{Mulligan}, mas podemos modelá-lo também como um MDP,
(na maioria dos casos\footnote{Um jogo normal de \textit{Magic} não tem um horizonte finito, pois há
inúmeras maneiras de retardar indefinidamente o fim do baralho (como voltar cartas da pilha de descarte para o baralho). Neste trabalho, a versão
simplificada do jogo com certeza terminará, no máximo, em 60 turnos, quando algum baralho acabar.}, de horizonte finito) tratando também das jogadas do oponente e da informação incompleta presente em sua mão.

\subsection{\textit{Magic} como um MDP}

Assim como detalhado em (\ref{ssec:mdp}) e feito com o problema do \textit{Mulligan}, precisamos definir os conjuntos $S, A, P$ e $R$ para caracterizar
o problema como um MDP.
\begin{itemize}
\item $S$: Cada estado no jogo representa uma diferente configuração entre pontos de vida dos jogadores ($v_1$ e $v_2$), cartas na mão do agente (lista $H$), quantidade de cartas na mão do agente e do oponente ($h_1$ e $h_2$) e nos dois baralhos ($d_1$ e $d_2$),  cartas nos cemitérios dos dois jogadores (listas $G_1$ e $G_2$) e por fim as cartas presentes no campo de batalha (duas listas, $B_1$ e $B_2$), bem como seus estados (virado, desvirado).

\vskip1ex

É preciso que o estado represente também algumas outras informações, como quem é o jogador ativo (representado por $ac_1$, $ac_2$), em qual fase o turno se encontra, quais criaturas entraram no campo de batalha neste turno (pois não poderão atacar) e quais criaturas estão atacando/bloqueando. Todas as possibilidades de estados formam o conjunto $S$ (dependendo das cartas
que compuserem os baralhos, o conjunto $S$ pode ser infinito). Formalmente, então, temos
\begin{equation}
  S := \begin{lrdcases} v_1, v_2 \in \mathbb{Z}, \\
                        act_1, act_2 \in \{0, 1\}, \\
                        fase \in \{Principal, Combate\} \\
                        H \subseteq \Omega, \\
                        h_1, h_2 \in \mathbb{N}, \\
                        d_1, d_2 \in \mathbb{N}, \\
                        G_1, G_2 \subseteq \Omega, \\
                        B_1, B_2 \subseteq \Omega^*
                      \end{lrdcases},
\end{equation}
onde $\Omega$ é o conjunto de todas as cartas e $\Omega^*$ é o conjunto das chamadas \textit{permanentes}, ou seja, cartas na mesa,
cada uma com uma carta relacionada mais os atributos mencionados (virada ou desvirada, se pode ou não atacar e se está atacando
ou bloqueando).
\item $A$ : Para definir as ações possíveis, devemos pensar na estrutura de um turno: \textit{Primeira Fase Principal - Combate - Segunda Fase Principal}. As duas fases principais funcionam do mesmo jeito. Assim, examinaremos cada fase separadamente:

\subsubsection{Fase Principal}

Durante a Fase Principal o jogador ativo pode jogar cartas. Para que o conjunto de ações $A^P$ em uma Fase Principal seja não-vazio, é necessário que o agente seja o jogador ativo (o jogador ativo alterna todo turno). Definimos $A^P$ da seguinte maneira, onde cada ação significa jogar uma carta (fora a ação de passe) e pode ser atribuída aos seguintes subconjuntos, cada um com condições próprias:

\begin{equation*}
  A^P := \begin{lrdcases} Land, \hspace{2.58cm}  \textrm{\hfill se o jogador não jogou terreno neste turno}, \\
                          Creature(c),\hspace{1.53cm} \textrm{se o jogador possui $c$ terrenos desvirados na mesa}, \\
                          Sorcery(c, T),\hspace{1.33cm} \textrm{se o jogador possui $c$ terrenos desvirados na mesa e $T$ são alvos válidos}, \\
                          CreatWithEff(c, T),\ \textrm{se o jogador possui $c$ terrenos desvirados na mesa e $T$ são alvos válidos}, \\
                          Pass,\hspace{2.6cm} \textrm{termina a fase (sempre possível).}
         \end{lrdcases}
\end{equation*}

Cada terreno só pode ser jogado se o jogador ainda não jogou um neste turno. Criaturas precisam do número de terrenos desvirados descrito em seu custo para serem jogadas. Feitiços, além do custo, precisam de alvos válidos para serem jogados (por exemplo, o feitiço ``Flame Slash'' lê, em português, ``Golpe Ardente causa 4 pontos de dano à criatura alvo.''. Dessa maneira, este feitiço só pode ser jogado se existe pelo menos uma criatura em jogo). Se uma criatura tem um efeito desencadeado quando entra em campo, por sua vez, esta criatura pode ser jogada mesmo se não existem alvos válidos para seu efeito (neste caso, o efeito simplesmente não acontece). Por fim, a ação $Pass$ termina a fase: se o jogador estiver na primeira fase principal, passa para o combate, se estiver na segunda, termina o turno. Toda ação $a \in A^P$ leva $s$ a um estado $s'$ com probabilidade $P(s' | s, a) = 1$.

\vskip1ex
O exemplo a seguir demonstra uma sequência de estados em uma fase principal e as ações legais correspondentes.

\newpage

\subsubsection{Exemplo - Fase Principal}
\input{mainphaseexample.tex}

\newpage

\subsubsection{Combate}

O combate é bem diferente da fase principal, pois não há jogada de cartas ou informação incompleta: tudo acontece com as criaturas já no campo de batalha. Sua estrutura é a seguinte: o jogador ativo \textit{declara atacantes}, ou seja, escolhe quais das suas criaturas atacarão e, em seguida, seu oponente \textit{declara bloqueadores}, escolhendo quais das suas criaturas bloquearão cada criatura atacante. Após isso, cada criatura atacante causa dano igual a seu poder às criaturas que a bloquearam ou ao jogador defensor (caso não tenha sido bloqueada), e cada criatura bloqueadora causa dano igual a seu poder à criatura que bloqueou. Todo dano é causado ao mesmo tempo. Por fim, cada criatura com dano maior ou igual à sua resistência é destruída: sua carta sai do campo de batalha e passa para a pilha de descarte correspondente.\footnote{Nesta seção não trataremos das \textit{habilidades de criatura} relevantes para o combate, de maneira a simplificar as explicações. Trataremos melhor disso mais a frente.}

\vskip1ex

O conjunto $A^C_1$ de ações do jogador ativo no combate, portanto, é o conjunto de escolhas de todas as combinações de criaturas atacantes (incluindo nenhuma). Dado que o jogador deve escolher alguma combinação, \begin{equation}|A^C_1| = \sum\limits_{i = 0}^{N}\binom{N}{i} = 2^N,\end{equation} onde $N$ é o número de criaturas que podem atacar na mesa do jogador ativo.

\vskip1ex

O conjunto $A^C_2$ de ações do jogador não-ativo durante o combate, por sua vez, é o conjunto de escolhas de todas as combinações de criaturas bloqueadoras e aquelas que estas bloqueiam. Como cada criatura desvirada pode bloquear até uma criatura atacante, temos que \begin{equation} |A^C_2| = (N' + 1)^M \le (N + 1)^M, \end{equation} onde $N'$ é o número de criaturas atacantes e $M$ o número de criaturas aptas a bloquearem.

\vskip1ex

Assim como na fase principal, cada ação $a \in \left\{A^C_1, A^C_2\right\}$ no estado $s$ tomada tem probabilidade $P(s'| s, a) = 1$ para o estado $s'$ sucessor previsto pelas regras.

\vskip1ex

Nas próximas páginas demonstraremos por exemplos os estados e conjuntos de ações (de ambos jogadores) em uma fase de combate.

\newpage
\subsubsection{Exemplo - Combate}
\input{combatexample.tex}


\item $R$ : Por fim, precisamos definir as recompensas por sair de cada estado. Uma boa definição inicial leva em conta os pontos de vida do agente e do oponente, assim como as ``presenças de campo'', termo vago que dá a ideia de progresso no jogo. Escolhemos medir a ``presença de campo'' de cada jogador com o dano que suas criaturas podem causar, ou seja, a soma do poder de todas as suas criaturas. Assim, dados pontos de vida $v_1, v_2$ respectivos do agente e seu oponente e seus conjuntos de permanentes $B_1, B_2$, temos

\begin{equation}
  R(s'|s, a) = \begin{cases}
              -\gamma, &\textrm{ caso $v_1 \le 0$,} \\
              +\gamma, &\textrm{ caso $v_2 \le 0$,} \\
              v_1 + v_2 + \sum\limits_{e \in B_1} pow(e) - \sum\limits_{e \in B_2} pow(e), &\textrm{ cc.}
            \end{cases},
\end{equation}
onde $\gamma$ deve ser uma recompensa para o agente suficientemente alta para incentivar a derrota do oponente e evitar a própria. A função $pow(e)$ retorna o poder da permanente $e$.

\vskip1ex

Podemos, então, calcular as recompensas de acordo com $R$ por sair dos estados nos exemplos demonstrados por meio das ações escolhidas:

\begin{itemize}
  \item $R(s_2 | s_1, Mountain) = v_1 - v_2 = 10 - 10 = 0.$
  \item $R(s_3 | s_2, PensiveMinotaur(3)) = v_1 - v_2 + pow(PensiveMinotaur) = 0 + 2 = 2.$
  \item $R(s_4 | s_3, FlameSlash(1, PensiveMinotaur)) = v_1 - v_2 + 0 = 0.$
\end{itemize}

Vamos examinar agora as recompensas no exemplo de combate tomando como agente o jogador defensor (portanto, as recompensas são contrárias - $v_2$ e $B_2$ são relativos aos agentes):

\begin{itemize}
  \item $R(t_3 | t_2, \{WalkingCorpse1 : GrizzlyBears2, WalkingCorpse2 : None\}) = v_2 - v_1 + \sum\limits_e(pow(e) : e \in B_2) - \sum\limits_e(pow(e) : e \in B_1) = 7 - 10 + 2 - 5 = -6.$
  \item $R(t'_3| t_2, \{WalkingCorpse1 : GrizzlyBears2, WalkingCorpse2 : CentaurCourser\}) = 10 - 10 + 0 - 3 = -3.$
  \item $R(t''_3| t_2, \{WalkingCorpse1 : CentaurCourser, WalkingCorpse2 : CentaurCourser\}) = 8 - 10 + 2 - 2 = -2.$
\end{itemize}
Estas recompensas refletem a noção de que o estado $t''_3$ é mais desejável para o jogador defensor do que os outros.

\end{itemize}

\chapter{Resultados}

\begin{thebibliography}{1}
  \bibitem{exemploMDP}Andrew Schaefer {\em Markov Decision Processes} 2006
\end{thebibliography}

\end{document}
