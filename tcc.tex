\documentclass[dvipsnames]{book}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{wrapfig}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{diagbox, eqparbox, hhline}
\usepackage{mathtools}
% \usepackage{caption}
\usepackage{mdframed}
\usepackage{fancyvrb}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{textcomp}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{caption}

\makeatletter
\newcases{lrdcases}
  {\quad}
  {$\m@th\displaystyle{##}$\hfil}
  {$\m@th\displaystyle{##}$\hfil}
  {\lbrace}
  {\rbrace}
\newcases{lrdcases*}
  {\quad}
  {$\m@th\displaystyle{##}$\hfil}
  {{##}\hfil}
  {\lbrace}
  {\rbrace}
\makeatother

\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\newcommand{\ind}{\hspace{0.8cm}}

\input{codeformatting.tex}

\begin{document}

  \begin{titlepage}
  \begin{center}
   {\huge\bfseries Inteligência Artificial \\ em \textit{Magic: the Gathering}\\}
   % ----------------------------------------------------------------
   \vspace{1.5cm}
   {\bfseries Guilherme Souto Schützer}\\[5pt]
   guischutzer@gmail.com\\[14pt]
   \vspace{0.5cm}
   {\bfseries Tomás Marcondes Bezerra Paim}\\[5pt]
   tomasbmp@gmail.com\\[14pt]
    % ----------------------------------------------------------------
   \vspace{2cm}
  {\begin{figure}[!h]
          \centering
              \includegraphics[width=0.25\textwidth]{picstcc/ime.png}
  \end{figure}}
   \vspace{0.4cm}
 \end{center}
  \end{titlepage}

\chapter*{Objetivo}
\textbf{Magic: The Gathering} é um jogo de cartas criado em 1993 por
Richard Garfield que introduziu o conceito moderno de \textit{trading
card game} (jogo de cartas colecionáveis). Com um acervo de mais de 15
mil cartas diferentes, os jogadores devem criar baralhos de 60 cartas
(normalmente podendo haver repetição de até quatro cartas iguais) e
competir, normalmente em jogos um contra um.
\par Durante o jogo, os jogadores têm que lidar com informações
conhecidas (as cartas já jogadas previamente e as cartas em suas mãos) e
informações desconhecidas (as cartas na mão de seu oponente e a ordem
das cartas em seu baralho), o que faz com que seja praticamente
impossível ter informação perfeita. Além disso, ambos os jogadores podem
agir a praticamente qualquer momento dentro de um turno, o que adiciona
uma camada a mais de complexidade.
\par Já existem inteligências artificiais feitas para jogar
\textbf{Magic}, mas devido à complexidade do jogo, nenhuma inteligência
artificial consegue ser realmente boa no jogo (por exemplo, elas não
costumam levar em consideração as cartas que estão na sua mão, então é
muito fácil fazer com que a IA sempre ``morda sua isca'').
\par Nosso objetivo com o trabalho será entender o problema e criar a
nossa versão de uma inteligência artificial para uma versão simplificada
do jogo (limitando o conjunto de cartas disponíveis, adicionando
restrições à construção dos baralhos e simplificando algumas regras do
jogo).

\input{intro.tex}

\input{implementacao.tex}

\newpage
\input{modelagem.tex}

\chapter{Resultados}
Neste capítulo gostaríamos de analisar os resultados obtidos aplicando os algoritmos descritos no
capítulo anterior.

\section{Mulligan}
A política encontrada com a iteração de valor faz bastante sentido se levarmos em consideração a
simplificação de limitar a informação das cartas na mão ao fato dela ser terreno ou não. Uma
maneira de deixar a modelagem mais real seria levar em consideração o custo de mana dos cards
não-terreno. Isso aumentaria enormemente a quantidade de estados possíveis (supondo que as cartas
não-terreno do deck tenham custo de mana entre $1$ e $5$, uma mão com duas cartas teria
$\sum\limits_{i=1}^{6}i = 21$ representações possíveis de estados ao invés de $3$, como acontece
com a modelagem que escolhemos), mas essa modelagem ainda estaria desconsiderando informações
relevantes na decisão do mulligan, como por exemplo se as cartas na mão inicial se encaixam na
estratégia definida pelo jogador para combater o deck adversário. De uma maneira geral, estamos
satisfeitos com os resultados obtidos, uma vez que o agente consegue mitigar a aleatoriedade
tomando decisões que aumentam suas chances de ter um jogo justo.

\section{O Jogo}
Após rodar os experimentos várias vezes e analisar os resultados, conseguimos descrever o
comportamento do agente dentro do jogo como agressivo. Já que escolhemos uma implementação que
leva em consideração apenas o turno atual, o agente não leva em consideração o ataque do oponente
no turno seguinte, e portanto escolhe os atacantes sem pensar em quais de suas criaturas seriam
boas bloqueadoras para impedir que o oponente estabeleça uma vantagem ou até mesmo ganhe o jogo.

Rodamos 70 testes com as configurações possíveis de agente inteligente ou aleatório controlando
cada um dos decks, e obtivemos os seguintes resultados:
\begin{itemize}
  \item \textbf{Aleatório x Aleatório:} Nessa configuração o deck Branco ganhou $71,8\%$ das vezes.
  Esse comportamento é esperado, pois o deck Vermelho tem uma quantidade maior de cartas que podem
  ter alvo tanto nas criaturas do controlador quanto nas do oponente, fazendo com que muitas vezes
  o agente mate suas próprias criaturas ou jogue uma carta que causa dano em si mesmo, enquanto o
  deck Branco tem menos cartas que possibilitam jogadas ruins.

  \item \textbf{Aleatório x Inteligente:} Jogamos com as duas configurações possíveis, e nas duas
  o agente com o algoritmo de busca se saiu muito melhor que o oponente: $95,9\%$ quando no
  controle do deck Branco, e $97,2\%$ quando controlando o deck Vermelho. Novamente um resultado
  esperado, dado que o agente aleatório demora turnos para jogar seu primeiro terreno enquanto o
  agente inteligente joga terrenos sempre que possível, o que possibilita que jogue suas cartas
  muito antes.

  \item \textbf{Inteligente x Inteligente:} Esta configuração é a mais interessante, uma vez que
  ambos os agentes jogaram tentando maximizar a recompensa. O resultado obtido foi $76,5\%$ de
  vitórias para o agente com o deck vermelho. Novamente, um resultado esperado, uma vez que o
  comportamento agressivo beneficia o deck vermelho.
\end{itemize}

\chapter{Considerações Finais}
Modelar um problema de inteligência artificial do zero, o que possibilitou com que aprofundássemos
nossos conhecimentos na área, estudando diferentes métodos de modelagem e algoritmos para extração
de política.

Implementar o nosso próprio cliente fez com que trabalhássemos com orientação a objetos em um
projeto grande, o que não havíamos feito muito durante as disciplinas da graduação. O cliente
facilitou a implementação dos agentes, uma vez que tínhamos conhecimento total da plataforma, mas
por outro lado impossibilitou que testássemos os agentes corretamente até que o jogo estivesse
funcionando corretamente, o que acabou se mostrando mais trabalhoso que o esperado.

\begin{thebibliography}{1}
  \bibitem{exemploMDP}Andrew Schaefer - {\em Markov Decision Processes} - 2006 - http://egon.cheme.cmu.edu/ewo/docs/SchaeferMDP.pdf
  \bibitem{fonteMDP}Jerônimo Pellegrini, Jacques Wainer - {\em Processos de Decisão de Markov: um tutorial} - 2007 - https://pdfs.semanticscholar.org/294f/694ae723a787f25043265fb3e660f62c573f.pdf
  \bibitem{livro}Stuart Russel, Peter Norvig - {\em Artificial Intelligence: A Modern Approach (3rd Edition)} - 2009
  \bibitem{compRules}Wizards of the Coast - {\em Magic: The Gathering Comprehensive Rules} - 2018 - http://media.wizards.com/2018/downloads/MagicCompRules%2020180119.pdf
\end{thebibliography}

\end{document}
